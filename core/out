BB 0:
85 5 5
97 a a
b7 3 3
2d 0 0
preds (0): 
succs (2): 1 4 

BB 1:
25 7 7
preds (1): 0 
succs (2): 2 4 

BB 2:
b7 0 0
63 0 0
67 2 2
bf 0 0
7 ffffffb0 ffffffb0
f 0 0
61 0 0
15 0 0
preds (1): 1 
succs (2): 3 4 

BB 3:
18 0 0
b7 5 5
85 6 6
preds (1): 2 
succs (1): 4 

BB 4:
b7 0 0
95 0 0
preds (4): 3 0 1 2 
succs (0): 

b0 (flag: 0x0):
  %0 = call __built_in_func_5() // [0.insn]
  %1 = mod(64) %0[1.dst], 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %1[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %1[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %2 = lsh(64) %1[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %3 = add(64) R10[9.dst], 0xffffffb0(32)[9.imm],  // [9.insn]
  %4 = add(64) %3[10.dst], %2[10.src],  // [10.insn]
  %5 = loadraw u32 %4[11.src] // [11.insn]
  jeq(64) %5[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %6 = loadimm(imm64) 0x0 // [13.insn]
  %7 = call __built_in_func_6(%6, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
Starting IR Passes...
[32m------ Running Pass: remove_trivial_phi ------[0m
b0 (flag: 0x0):
  %0 = call __built_in_func_5() // [0.insn]
  %1 = mod(64) %0[1.dst], 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %1[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %1[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %2 = lsh(64) %1[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %3 = add(64) R10[9.dst], 0xffffffb0(32)[9.imm],  // [9.insn]
  %4 = add(64) %3[10.dst], %2[10.src],  // [10.insn]
  %5 = loadraw u32 %4[11.src] // [11.insn]
  jeq(64) %5[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %6 = loadimm(imm64) 0x0 // [13.insn]
  %7 = call __built_in_func_6(%6, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
[32m------ Running Pass: msan ------[0m
Found a stack pointer store at off -60
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  %1 = call __built_in_func_5() // [0.insn]
  %2 = mod(64) %1[1.dst], 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %2[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %2[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %3 = loadraw u8 R10+-8(+off)
  %4 = loadraw u8 R10+-9
  %5 = lsh(64) %2[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %6 = add(64) R10[9.dst], 0xffffffb0(32)[9.imm],  // [9.insn]
  %7 = add(64) %6[10.dst], %5[10.src],  // [10.insn]
  %8 = loadraw u32 %7[11.src] // [11.insn]
  jeq(64) %8[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %9 = loadimm(imm64) 0x0 // [13.insn]
  %10 = call __built_in_func_6(%9, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
[32m------ Running Pass: translate_throw ------[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  %1 = call __built_in_func_5() // [0.insn]
  %2 = mod(64) %1[1.dst], 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %2[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %2[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %3 = loadraw u8 R10+-8(+off)
  %4 = loadraw u8 R10+-9
  %5 = lsh(64) %2[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %6 = add(64) R10[9.dst], 0xffffffb0(32)[9.imm],  // [9.insn]
  %7 = add(64) %6[10.dst], %5[10.src],  // [10.insn]
  %8 = loadraw u32 %7[11.src] // [11.insn]
  jeq(64) %8[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %9 = loadimm(imm64) 0x0 // [13.insn]
  %10 = call __built_in_func_6(%9, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
[32m------ Running Pass: optimize_ir ------[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  %1 = call __built_in_func_5() // [0.insn]
  %2 = mod(64) %1[1.dst], 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %2[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %2[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %3 = lsh(64) %2[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %4 = add(64) R10[9.dst], 0xffffffb0(32)[9.imm],  // [9.insn]
  %5 = add(64) %4[10.dst], %3[10.src],  // [10.insn]
  %6 = loadraw u32 %5[11.src] // [11.insn]
  jeq(64) %6[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %7 = loadimm(imm64) 0x0 // [13.insn]
  %8 = call __built_in_func_6(%7, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
[32m------ Running Pass: change_fun_arg ------[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  %1 = call __built_in_func_5() // [0.insn]
  %2 = mod(64) %1[1.dst], 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %2[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %2[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %3 = lsh(64) %2[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %4 = add(64) R10[9.dst], 0xffffffb0(32)[9.imm],  // [9.insn]
  %5 = add(64) %4[10.dst], %3[10.src],  // [10.insn]
  %6 = loadraw u32 %5[11.src] // [11.insn]
  jeq(64) %6[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %7 = loadimm(imm64) 0x0 // [13.insn]
  %8 = call __built_in_func_6(%7, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
[32m------ Running Pass: change_call ------[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  %1 = call __built_in_func_5() // [0.insn]
  %2 = R0
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %3[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %4 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %5 = add(64) R10[9.dst], 0xffffffb0(32)[9.imm],  // [9.insn]
  %6 = add(64) %5[10.dst], %4[10.src],  // [10.insn]
  %7 = loadraw u32 %6[11.src] // [11.insn]
  jeq(64) %7[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %8 = loadimm(imm64) 0x0 // [13.insn]
  %9 = call __built_in_func_6(%8, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
[32m------ Running Pass: add_stack_offset ------[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  %1 = call __built_in_func_5() // [0.insn]
  %2 = R0
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %3[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %4 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %5 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  %6 = add(64) %5[10.dst], %4[10.src],  // [10.insn]
  %7 = loadraw u32 %6[11.src] // [11.insn]
  jeq(64) %7[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %8 = loadimm(imm64) 0x0 // [13.insn]
  %9 = call __built_in_func_6(%8, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
[32m------ Running Pass: to_cssa ------[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  %1 = call __built_in_func_5() // [0.insn]
  %2 = R0
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %3[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %4 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %5 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  %6 = add(64) %5[10.dst], %4[10.src],  // [10.insn]
  %7 = loadraw u32 %6[11.src] // [11.insn]
  jeq(64) %7[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %8 = loadimm(imm64) 0x0 // [13.insn]
  %9 = call __built_in_func_6(%8, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
IR Passes Ended!
[32m----- CG: PHI Removal -----[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  %1 = call __built_in_func_5() // [0.insn]
  %2 = R0
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %3[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %4 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %5 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  %6 = add(64) %5[10.dst], %4[10.src],  // [10.insn]
  %7 = loadraw u32 %6[11.src] // [11.insn]
  jeq(64) %7[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %8 = loadimm(imm64) 0x0 // [13.insn]
  %9 = call __built_in_func_6(%8, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  ret 0x0(32)[17.imm] // [18.insn]
[32m----- CG: Changing ret -----[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  %1 = call __built_in_func_5() // [0.insn]
  %2 = R0
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %3[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %4 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %5 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  %6 = add(64) %5[10.dst], %4[10.src],  // [10.insn]
  %7 = loadraw u32 %6[11.src] // [11.insn]
  jeq(64) %7[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %8 = loadimm(imm64) 0x0 // [13.insn]
  %9 = call __built_in_func_6(%8, 0x5(32)[15.imm]) // [16.insn]
b4 (flag: 0x0):
  R0 = 0x0(32)[17.imm]
  ret  // [18.insn]
[32m----- CG: Changing calls -----[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  R0 = call __built_in_func_5() // [0.insn]
  %2 = R0
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %3[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %4 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %5 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  %6 = add(64) %5[10.dst], %4[10.src],  // [10.insn]
  %7 = loadraw u32 %6[11.src] // [11.insn]
  jeq(64) %7[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %8 = loadimm(imm64) 0x0 // [13.insn]
  R1 = %8
  R2 = 0x5(32)[15.imm]
  R0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  R0 = 0x0(32)[17.imm]
  ret  // [18.insn]
[32m----- CG: Spilling Arrays -----[0m
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  R0 = call __built_in_func_5() // [0.insn]
  %2 = R0
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %3[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %4 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %5 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  %6 = add(64) %5[10.dst], %4[10.src],  // [10.insn]
  %7 = loadraw u32 %6[11.src] // [11.insn]
  jeq(64) %7[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %8 = loadimm(imm64) 0x0 // [13.insn]
  R1 = %8
  R2 = 0x5(32)[15.imm]
  R0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  R0 = 0x0(32)[17.imm]
  ret  // [18.insn]
[32m----- Register allocation iteration 0 -----[0m
--------------
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
--
Gen:
Kill: %0
In: R10
Out: %0 R10
-------------
  storeraw u64 %0+56 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+48 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+40 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+32 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+24 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+16 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+8 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: R10
-------------
  R0 = call __built_in_func_5() // [0.insn]
--
Gen:
Kill: R0
In: R10
Out: R0 R10
-------------
  %2 = R0
--
Gen: R0
Kill: %2
In: R0 R10
Out: %2 R10
-------------
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
--
Gen: %2
Kill: %3
In: %2 R10
Out: %3 R10
-------------
  jgt(64) 0x3(32)[3.dst], %3[3.src], b1/b4 // [3.insn]
--
Gen: %3
Kill:
In: %3 R10
Out: %3 R10
-------------
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
--
Gen: %3
Kill:
In: %3 R10
Out: R10 %3
-------------
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
--
Gen: R10
Kill:
In: R10 %3
Out: %3 R10
-------------
  %4 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
--
Gen: %3
Kill: %4
In: %3 R10
Out: R10 %4
-------------
  %5 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
--
Gen: R10
Kill: %5
In: R10 %4
Out: %5 %4
-------------
  %6 = add(64) %5[10.dst], %4[10.src],  // [10.insn]
--
Gen: %5 %4
Kill: %6
In: %5 %4
Out: %6
-------------
  %7 = loadraw u32 %6[11.src] // [11.insn]
--
Gen: %6
Kill: %7
In: %6
Out: %7
-------------
  jeq(64) %7[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
--
Gen: %7
Kill:
In: %7
Out:
-------------
b3 (flag: 0x0):
  %8 = loadimm(imm64) 0x0 // [13.insn]
--
Gen:
Kill: %8
In:
Out: %8
-------------
  R1 = %8
--
Gen: %8
Kill: R1
In: %8
Out:
-------------
  R2 = 0x5(32)[15.imm]
--
Gen:
Kill: R2
In:
Out:
-------------
  R0 = call __built_in_func_6() // [16.insn]
--
Gen:
Kill: R0
In:
Out:
-------------
b4 (flag: 0x0):
  R0 = 0x0(32)[17.imm]
--
Gen:
Kill: R0
In:
Out:
-------------
  ret  // [18.insn]
--
Gen:
Kill:
In:
Out:
-------------
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  R0 = call __built_in_func_5() // [0.insn]
  %2 = R0
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], %3[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %4 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %5 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  %6 = add(64) %5[10.dst], %4[10.src],  // [10.insn]
  %7 = loadraw u32 %6[11.src] // [11.insn]
  jeq(64) %7[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %8 = loadimm(imm64) 0x0 // [13.insn]
  R1 = %8
  R2 = 0x5(32)[15.imm]
  R0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  R0 = 0x0(32)[17.imm]
  ret  // [18.insn]
Conflicting graph:
%0(sp+-64): R10
%2: R10
%3: R10
%4: R10 %5
%5: %4
%6:
%7:
%8:
Allocate r0 for %2
Allocate r0 for %3
Allocate r0 for %4
Allocate r1 for %5
Allocate r0 for %6
Allocate r0 for %7
Allocate r0 for %8
Conflicting graph (after coloring):
%0(sp+-64): R10
%2(r0): R10
%3(r0): R10
%4(r0): R10 %5
%5(r1): %4
%6(r0):
%7(r0):
%8(r0):
[32m----- CG: After RA -----[0m
b0 (flag: 0x0):
  sp+-64 = allocarray <u64 x 8>
  storeraw u64 sp+-64+56 0x0(32)
  storeraw u64 sp+-64+48 0x0(32)
  storeraw u64 sp+-64+40 0x0(32)
  storeraw u64 sp+-64+32 0x0(32)
  storeraw u64 sp+-64+24 0x0(32)
  storeraw u64 sp+-64+16 0x0(32)
  storeraw u64 sp+-64+8 0x0(32)
  storeraw u64 sp+-64 0x0(32)
  r0 = call __built_in_func_5() // [0.insn]
  r0 = r0
  r0 = mod(64) r0, 0xa(32)[1.imm],  // [1.insn]
  jgt(64) 0x3(32)[3.dst], r0[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) r0[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 r10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  r0 = lsh(64) r0[7.dst], 0x2(32)[7.imm],  // [7.insn]
  r1 = add(64) r10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  r0 = add(64) r1[10.dst], r0[10.src],  // [10.insn]
  r0 = loadraw u32 r0[11.src] // [11.insn]
  jeq(64) r0[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  r0 = loadimm(imm64) 0x0 // [13.insn]
  r1 = r0
  r2 = 0x5(32)[15.imm]
  r0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  r0 = 0x0(32)[17.imm]
  ret  // [18.insn]
Warning: using const as the first operand of conditional jump may impact performance.
[32m----- CG: Spilling -----[0m
b0 (flag: 0x0):
  sp+-64 = allocarray <u64 x 8>
  storeraw u64 sp+-64+56 0x0(32)
  storeraw u64 sp+-64+48 0x0(32)
  storeraw u64 sp+-64+40 0x0(32)
  storeraw u64 sp+-64+32 0x0(32)
  storeraw u64 sp+-64+24 0x0(32)
  storeraw u64 sp+-64+16 0x0(32)
  storeraw u64 sp+-64+8 0x0(32)
  storeraw u64 sp+-64 0x0(32)
  r0 = call __built_in_func_5() // [0.insn]
  r0 = r0
  r0 = mod(64) r0, 0xa(32)[1.imm],  // [1.insn]
  r1 = 0x3(32)[3.dst]
  jgt(64) r1, r0[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) r0[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 r10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  r0 = lsh(64) r0[7.dst], 0x2(32)[7.imm],  // [7.insn]
  r1 = add(64) r10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  r0 = add(64) r0[10.src], r1[10.dst],  // [10.insn]
  r0 = loadraw u32 r0[11.src] // [11.insn]
  jeq(64) r0[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  r0 = loadimm(imm64) 0x0 // [13.insn]
  r1 = r0
  r2 = 0x5(32)[15.imm]
  r0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  r0 = 0x0(32)[17.imm]
  ret  // [18.insn]
Need to spill...
[32m----- Register allocation iteration 1 -----[0m
--------------
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
--
Gen:
Kill: %0
In: R10
Out: %0 R10
-------------
  storeraw u64 %0+56 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+48 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+40 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+32 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+24 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+16 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0+8 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: %0 R10
-------------
  storeraw u64 %0 0x0(32)
--
Gen: %0
Kill:
In: %0 R10
Out: R10
-------------
  R0 = call __built_in_func_5() // [0.insn]
--
Gen:
Kill: R0
In: R10
Out: R0 R10
-------------
  %2 = R0
--
Gen: R0
Kill: %2
In: R0 R10
Out: %2 R10
-------------
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
--
Gen: %2
Kill: %3
In: %2 R10
Out: %3 R10
-------------
  R1 = 0x3(32)[3.dst]
--
Gen:
Kill: R1
In: %3 R10
Out: R1 %3 R10
-------------
  jgt(64) R1, %3[3.src], b1/b4 // [3.insn]
--
Gen: R1 %3
Kill:
In: R1 %3 R10
Out: %3 R10
-------------
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
--
Gen: %3
Kill:
In: %3 R10
Out: R10 %3
-------------
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
--
Gen: R10
Kill:
In: R10 %3
Out: %3 R10
-------------
  %5 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
--
Gen: %3
Kill: %5
In: %3 R10
Out: R10 %5
-------------
  %6 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
--
Gen: R10
Kill: %6
In: R10 %5
Out: %5 %6
-------------
  %7 = add(64) %5[10.src], %6[10.dst],  // [10.insn]
--
Gen: %5 %6
Kill: %7
In: %5 %6
Out: %7
-------------
  %8 = loadraw u32 %7[11.src] // [11.insn]
--
Gen: %7
Kill: %8
In: %7
Out: %8
-------------
  jeq(64) %8[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
--
Gen: %8
Kill:
In: %8
Out:
-------------
b3 (flag: 0x0):
  %9 = loadimm(imm64) 0x0 // [13.insn]
--
Gen:
Kill: %9
In:
Out: %9
-------------
  R1 = %9
--
Gen: %9
Kill: R1
In: %9
Out:
-------------
  R2 = 0x5(32)[15.imm]
--
Gen:
Kill: R2
In:
Out:
-------------
  R0 = call __built_in_func_6() // [16.insn]
--
Gen:
Kill: R0
In:
Out:
-------------
b4 (flag: 0x0):
  R0 = 0x0(32)[17.imm]
--
Gen:
Kill: R0
In:
Out:
-------------
  ret  // [18.insn]
--
Gen:
Kill:
In:
Out:
-------------
b0 (flag: 0x0):
  %0 = allocarray <u64 x 8>
  storeraw u64 %0+56 0x0(32)
  storeraw u64 %0+48 0x0(32)
  storeraw u64 %0+40 0x0(32)
  storeraw u64 %0+32 0x0(32)
  storeraw u64 %0+24 0x0(32)
  storeraw u64 %0+16 0x0(32)
  storeraw u64 %0+8 0x0(32)
  storeraw u64 %0 0x0(32)
  R0 = call __built_in_func_5() // [0.insn]
  %2 = R0
  %3 = mod(64) %2, 0xa(32)[1.imm],  // [1.insn]
  R1 = 0x3(32)[3.dst]
  jgt(64) R1, %3[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) %3[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 R10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  %5 = lsh(64) %3[7.dst], 0x2(32)[7.imm],  // [7.insn]
  %6 = add(64) R10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  %7 = add(64) %5[10.src], %6[10.dst],  // [10.insn]
  %8 = loadraw u32 %7[11.src] // [11.insn]
  jeq(64) %8[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  %9 = loadimm(imm64) 0x0 // [13.insn]
  R1 = %9
  R2 = 0x5(32)[15.imm]
  R0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  R0 = 0x0(32)[17.imm]
  ret  // [18.insn]
Conflicting graph:
%0(sp+-64): R10
%2: R10
%3: R10 R1
%5: R10 %6
%6: %5
%7:
%8:
%9:
Allocate r0 for %2
Allocate r0 for %3
Allocate r0 for %5
Allocate r1 for %6
Allocate r0 for %7
Allocate r0 for %8
Allocate r0 for %9
Conflicting graph (after coloring):
%0(sp+-64): R10
%2(r0): R10
%3(r0): R10 R1
%5(r0): R10 %6
%6(r1): %5
%7(r0):
%8(r0):
%9(r0):
[32m----- CG: After RA -----[0m
b0 (flag: 0x0):
  sp+-64 = allocarray <u64 x 8>
  storeraw u64 sp+-64+56 0x0(32)
  storeraw u64 sp+-64+48 0x0(32)
  storeraw u64 sp+-64+40 0x0(32)
  storeraw u64 sp+-64+32 0x0(32)
  storeraw u64 sp+-64+24 0x0(32)
  storeraw u64 sp+-64+16 0x0(32)
  storeraw u64 sp+-64+8 0x0(32)
  storeraw u64 sp+-64 0x0(32)
  r0 = call __built_in_func_5() // [0.insn]
  r0 = r0
  r0 = mod(64) r0, 0xa(32)[1.imm],  // [1.insn]
  r1 = 0x3(32)[3.dst]
  jgt(64) r1, r0[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) r0[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 r10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  r0 = lsh(64) r0[7.dst], 0x2(32)[7.imm],  // [7.insn]
  r1 = add(64) r10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  r0 = add(64) r0[10.src], r1[10.dst],  // [10.insn]
  r0 = loadraw u32 r0[11.src] // [11.insn]
  jeq(64) r0[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  r0 = loadimm(imm64) 0x0 // [13.insn]
  r1 = r0
  r2 = 0x5(32)[15.imm]
  r0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  r0 = 0x0(32)[17.imm]
  ret  // [18.insn]
[32m----- CG: Spilling -----[0m
b0 (flag: 0x0):
  sp+-64 = allocarray <u64 x 8>
  storeraw u64 sp+-64+56 0x0(32)
  storeraw u64 sp+-64+48 0x0(32)
  storeraw u64 sp+-64+40 0x0(32)
  storeraw u64 sp+-64+32 0x0(32)
  storeraw u64 sp+-64+24 0x0(32)
  storeraw u64 sp+-64+16 0x0(32)
  storeraw u64 sp+-64+8 0x0(32)
  storeraw u64 sp+-64 0x0(32)
  r0 = call __built_in_func_5() // [0.insn]
  r0 = r0
  r0 = mod(64) r0, 0xa(32)[1.imm],  // [1.insn]
  r1 = 0x3(32)[3.dst]
  jgt(64) r1, r0[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) r0[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 r10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  r0 = lsh(64) r0[7.dst], 0x2(32)[7.imm],  // [7.insn]
  r1 = add(64) r10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  r0 = add(64) r0[10.src], r1[10.dst],  // [10.insn]
  r0 = loadraw u32 r0[11.src] // [11.insn]
  jeq(64) r0[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  r0 = loadimm(imm64) 0x0 // [13.insn]
  r1 = r0
  r2 = 0x5(32)[15.imm]
  r0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  r0 = 0x0(32)[17.imm]
  ret  // [18.insn]
Register allocation finished in 2 iterations
[32m----- CG: After RA & Spilling -----[0m
b0 (flag: 0x0):
  sp+-64 = allocarray <u64 x 8>
  storeraw u64 sp+-64+56 0x0(32)
  storeraw u64 sp+-64+48 0x0(32)
  storeraw u64 sp+-64+40 0x0(32)
  storeraw u64 sp+-64+32 0x0(32)
  storeraw u64 sp+-64+24 0x0(32)
  storeraw u64 sp+-64+16 0x0(32)
  storeraw u64 sp+-64+8 0x0(32)
  storeraw u64 sp+-64 0x0(32)
  r0 = call __built_in_func_5() // [0.insn]
  r0 = r0
  r0 = mod(64) r0, 0xa(32)[1.imm],  // [1.insn]
  r1 = 0x3(32)[3.dst]
  jgt(64) r1, r0[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) r0[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 r10[6.dst]+-60(+off) 0x0(32)[6.src] // [6.insn]
  r0 = lsh(64) r0[7.dst], 0x2(32)[7.imm],  // [7.insn]
  r1 = add(64) r10[9.dst], hole(0xffffffb0(32))[9.imm],  // [9.insn]
  r0 = add(64) r0[10.src], r1[10.dst],  // [10.insn]
  r0 = loadraw u32 r0[11.src] // [11.insn]
  jeq(64) r0[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  r0 = loadimm(imm64) 0x0 // [13.insn]
  r1 = r0
  r2 = 0x5(32)[15.imm]
  r0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  r0 = 0x0(32)[17.imm]
  ret  // [18.insn]
[32m----- CG: Shifting stack access -----[0m
b0 (flag: 0x0):
  sp+-64 = allocarray <u64 x 8>
  storeraw u64 sp+-64+56 0x0(32)
  storeraw u64 sp+-64+48 0x0(32)
  storeraw u64 sp+-64+40 0x0(32)
  storeraw u64 sp+-64+32 0x0(32)
  storeraw u64 sp+-64+24 0x0(32)
  storeraw u64 sp+-64+16 0x0(32)
  storeraw u64 sp+-64+8 0x0(32)
  storeraw u64 sp+-64 0x0(32)
  r0 = call __built_in_func_5() // [0.insn]
  r0 = r0
  r0 = mod(64) r0, 0xa(32)[1.imm],  // [1.insn]
  r1 = 0x3(32)[3.dst]
  jgt(64) r1, r0[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) r0[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 r10[6.dst]+-124 0x0(32)[6.src] // [6.insn]
  r0 = lsh(64) r0[7.dst], 0x2(32)[7.imm],  // [7.insn]
  r1 = add(64) r10[9.dst], 0xffffff70(32)[9.imm],  // [9.insn]
  r0 = add(64) r0[10.src], r1[10.dst],  // [10.insn]
  r0 = loadraw u32 r0[11.src] // [11.insn]
  jeq(64) r0[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  r0 = loadimm(imm64) 0x0 // [13.insn]
  r1 = r0
  r2 = 0x5(32)[15.imm]
  r0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  r0 = 0x0(32)[17.imm]
  ret  // [18.insn]
[32m----- CG: Normalization -----[0m
b0 (flag: 0x0):
  sp+-64 = allocarray <u64 x 8>
  storeraw u64 r10+-8 0x0(32)
  storeraw u64 r10+-16 0x0(32)
  storeraw u64 r10+-24 0x0(32)
  storeraw u64 r10+-32 0x0(32)
  storeraw u64 r10+-40 0x0(32)
  storeraw u64 r10+-48 0x0(32)
  storeraw u64 r10+-56 0x0(32)
  storeraw u64 r10+-64 0x0(32)
  r0 = call __built_in_func_5() // [0.insn]
  r0 = mod(64) r0, 0xa(32)[1.imm],  // [1.insn]
  r1 = 0x3(32)[3.dst]
  jgt(64) r1, r0[3.src], b1/b4 // [3.insn]
b1 (flag: 0x0):
  jgt(64) r0[4.dst], 0x7(32)[4.imm], b2/b4 // [4.insn]
b2 (flag: 0x0):
  storeraw u32 r10[6.dst]+-124 0x0(32)[6.src] // [6.insn]
  r0 = lsh(64) r0[7.dst], 0x2(32)[7.imm],  // [7.insn]
  r1 = r10[9.dst]
  r1 = add(64) r1, 0xffffff70(32)[9.imm],  // [9.insn]
  r0 = add(64) r0[10.src], r1[10.dst],  // [10.insn]
  r0 = loadraw u32 r0[11.src] // [11.insn]
  jeq(64) r0[12.dst], 0x0(32)[12.imm], b3/b4 // [12.insn]
b3 (flag: 0x0):
  r0 = loadimm(imm64) 0x0 // [13.insn]
  r1 = r0
  r2 = 0x5(32)[15.imm]
  r0 = call __built_in_func_6() // [16.insn]
b4 (flag: 0x0):
  r0 = 0x0(32)[17.imm]
  ret  // [18.insn]
--------------------
Original Program, size 19:
[0] (85) call fun_+5#5
[1] (97) r0 %= 10
[2] (b7) r1 = 3
[3] (2d) if r1 > r0 goto pc+13
[4] (25) if r0 > 0x7 goto pc+12
[5] (b7) r1 = 0
[6] (63) *(u32 *)(r10 -60) = r1
[7] (67) r0 <<= 2
[8] (bf) r1 = r10
[9] (07) r1 += -80
[10] (0f) r1 += r0
[11] (61) r1 = *(u32 *)(r1 +0)
[12] (15) if r1 == 0x0 goto pc+4
[13] (18) r1 = 0x0 (imm64 ld)
[15] (b7) r2 = 5
[16] (85) call fun_+6#6
[17] (b7) r0 = 0
[18] (95) exit
--------------------
Rewritten Program, size 27:
[0] (7a) *(u64 *)(r10 -8) = 0
[1] (7a) *(u64 *)(r10 -16) = 0
[2] (7a) *(u64 *)(r10 -24) = 0
[3] (7a) *(u64 *)(r10 -32) = 0
[4] (7a) *(u64 *)(r10 -40) = 0
[5] (7a) *(u64 *)(r10 -48) = 0
[6] (7a) *(u64 *)(r10 -56) = 0
[7] (7a) *(u64 *)(r10 -64) = 0
[8] (85) call fun_+5#5
[9] (97) r0 %= 10
[10] (b7) r1 = 3
[11] (2d) if r1 > r0 goto pc+13
[12] (25) if r0 > 0x7 goto pc+12
[13] (62) *(u32 *)(r10 -124) = 0
[14] (67) r0 <<= 2
[15] (bf) r1 = r10
[16] (07) r1 += -144
[17] (0f) r0 += r1
[18] (61) r0 = *(u32 *)(r0 +0)
[19] (15) if r0 == 0x0 goto pc+5
[20] (18) r0 = 0x0 (imm64 ld)
[22] (bf) r1 = r0
[23] (b7) r2 = 5
[24] (85) call fun_+6#6
[25] (b7) r0 = 0
[26] (95) exit
